{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent Neural Network in NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return x * (x > 0)\n",
    "\n",
    "def relu_derivative(x):\n",
    "    return np.array(x * (x > 0) != 0, dtype='int')\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivate(x):\n",
    "    return sigmoid(x) * (1 - sigmoid(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "int2binary = {}\n",
    "\n",
    "num_range = 2**8\n",
    "\n",
    "_DIGITS = 8\n",
    "\n",
    "binary = np.unpackbits(np.array([range(num_range)],dtype=np.uint8).T,axis=1)\n",
    "for i in range(num_range):\n",
    "    int2binary[i] = binary[i]\n",
    "\n",
    "def data_generator(data_size):\n",
    "    data = np.zeros((data_size, _DIGITS*3))\n",
    "    for row_index in range(data_size):\n",
    "        a = np.random.randint(int(num_range/2))\n",
    "        b = np.random.randint(int(num_range/2))\n",
    "        for col_index in range(_DIGITS):\n",
    "            data[row_index, col_index*2] = int2binary[a][col_index]\n",
    "            data[row_index, col_index*2+1] = int2binary[b][col_index]\n",
    "        data[row_index, _DIGITS*2:] = int2binary[a + b]\n",
    "    return data\n",
    "\n",
    "def input_feed(data, batch_size):\n",
    "    for index in range(0, len(data), batch_size):\n",
    "        yield {'train_data': data[index:index + batch_size, :_DIGITS*2],\n",
    "               'target_data': data[index:index + batch_size, _DIGITS*2:]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Rnn:\n",
    "    \n",
    "    def __init__(self, input_dim):\n",
    "        self.h_size = 10\n",
    "        self.o_size = 1\n",
    "        self.batch_size = None\n",
    "        self.lrate = None\n",
    "        \n",
    "        self.layers = {\n",
    "            'input': [],\n",
    "            'hidden': [],\n",
    "            'output': []\n",
    "        }\n",
    "        \n",
    "        self.synapse_ih = {\n",
    "            'weights': np.random.rand(input_dim, self.h_size),\n",
    "            'biases': np.random.rand(1, self.h_size)\n",
    "        } \n",
    "        self.synapse_hh = {\n",
    "            'weights': np.random.rand(self.h_size, self.h_size)\n",
    "        }\n",
    "        self.synapse_ho = {\n",
    "            'weights': np.random.rand(self.h_size, self.o_size),\n",
    "            'biases': np.random.rand(1, self.o_size)\n",
    "        }\n",
    "    \n",
    "    def train(self, train_data, batch_generator, batch_size=1, epochs=10, lrate=0.01):\n",
    "        self.batch_size = batch_size\n",
    "        self.lrate = lrate\n",
    "        data = copy.deepcopy(train_data)\n",
    "        for epoch in range(epochs):\n",
    "            epoch_error = 0\n",
    "            data = sk.utils.shuffle(data)\n",
    "            for batch in batch_generator(data, self.batch_size):\n",
    "                prediction = np.array(self._forward_prop(batch['train_data'])).reshape(_DIGITS,self.batch_size).T\n",
    "                error = batch['target_data']-prediction\n",
    "                self._back_prop(error)\n",
    "            \n",
    "    def test(self):\n",
    "        pass\n",
    "    \n",
    "    def _predict(self):\n",
    "        pass\n",
    "    \n",
    "    def _forward_prop(self, x):\n",
    "        \"\"\"assumes x is a sequence input and first dim is seq length\"\"\"\n",
    "        self.layers['input'] = []\n",
    "        self.layers['hidden'] = [np.zeros((self.batch_size, self.h_size))]\n",
    "        self.layers['output'] = []\n",
    "        # TODO: different iterator\n",
    "        for index in range(_DIGITS):\n",
    "            self.layers['input'].append(np.atleast_2d(x[:,index*2:index*2+2]))\n",
    "            self.layers['hidden'].append(sigmoid(np.dot(self.layers['input'][-1], self.synapse_ih['weights']) + \n",
    "                                                      np.dot(self.layers['hidden'][-1], self.synapse_hh['weights']) +\n",
    "                                                      self.synapse_ih['biases']))\n",
    "            self.layers['output'].append(sigmoid(np.dot(self.layers['hidden'][-1], self.synapse_ho['weights']) +\n",
    "                                                       self.synapse_ho['biases']))\n",
    "        \n",
    "        return self.layers['output']\n",
    "        \n",
    "    def _back_prop(self, errors):\n",
    "        synapse_update_ih = {\n",
    "            'weights': np.zeros_like(self.synapse_ih['weights']),\n",
    "            'biases': np.zeros_like(self.synapse_ih['biases'])\n",
    "        }\n",
    "        synapse_update_hh = {\n",
    "            'weights': np.zeros_like(self.synapse_hh['weights'])\n",
    "        }\n",
    "        synapse_update_ho = {\n",
    "            'weights': np.zeros_like(self.synapse_ho['weights']),\n",
    "            'biases': np.zeros_like(self.synapse_ho['biases'])\n",
    "        }\n",
    "        \n",
    "        delta_hh = np.zeros((1, self.h_size))\n",
    "        delta_next_hh = np.zeros((1, self.h_size))\n",
    "        delta_ho = [np.multiply(sigmoid_derivate(self.layers['output'][index]), errors[:,index].reshape(self.batch_size, self.o_size)) for index in range(_DIGITS)]\n",
    "        \n",
    "        for index in range(len(errors)-1,-1,-1):\n",
    "            synapse_update_ho['weights'] +=  np.dot(self.layers['output'][index].T, delta_ho[index])\n",
    "            synapse_update_ho['biases'] +=  np.atleast_2d(delta_ho[index].sum(axis=0))\n",
    "\n",
    "            delta_hh = (np.dot(delta_next_hh, self.synapse_hh['weights'].T) + \n",
    "                         np.multiply(np.dot(delta_ho[index], self.synapse_ho['weights'].T), sigmoid_derivate(self.layers['hidden'][index+1])))\n",
    "\n",
    "            synapse_update_hh['weights'] += np.dot(self.layers['hidden'][index+1].T, np.atleast_2d(delta_hh))\n",
    "            \n",
    "            synapse_update_ih['weights'] += np.dot(self.layers['input'][index].T, np.atleast_2d(delta_hh))\n",
    "            synapse_update_ih['biases'] += np.atleast_2d(delta_hh.sum(axis=0))\n",
    "\n",
    "            delta_next_hh = delta_hh\n",
    "            \n",
    "        self.synapse_ih['weights'] += - self.lrate * (synapse_update_ih['weights']/self.batch_size)\n",
    "        self.synapse_hh['weights'] += - self.lrate * (synapse_update_hh['weights']/self.batch_size)\n",
    "        self.synapse_ho['weights'] += - self.lrate * (synapse_update_ho['weights']/self.batch_size)\n",
    "        \n",
    "        self.synapse_ih['biases'] += - self.lrate * (synapse_update_ih['biases']/self.batch_size)\n",
    "        self.synapse_ho['biases'] += - self.lrate * (synapse_update_ho['biases']/self.batch_size)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (2,1) and (3,10) not aligned: 1 (dim 1) != 3 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-467-d61ac986bc5f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mrnn_object\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mrnn_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_generator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_feed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-466-e80199a7373a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_data, batch_generator, batch_size, epochs, lrate)\u001b[0m\n\u001b[1;32m     35\u001b[0m                 \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_prop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train_data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_DIGITS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target_data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_back_prop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-466-e80199a7373a>\u001b[0m in \u001b[0;36m_back_prop\u001b[0;34m(self, errors)\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0msynapse_update_hh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weights'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'hidden'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelta_hh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0msynapse_update_ih\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weights'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelta_hh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m             \u001b[0msynapse_update_ih\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'biases'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelta_hh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (2,1) and (3,10) not aligned: 1 (dim 1) != 3 (dim 0)"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "data = data_generator(10)\n",
    "rnn_object = Rnn(input_dim=2, )\n",
    "rnn_object.train(train_data=data, batch_generator=input_feed, batch_size=3, epochs=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
